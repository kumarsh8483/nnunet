About the log layout:
There are two top level log folders azureml-logs and logs.
    1. azureml-logs: containing image building, pre, driver and post processing logs for ParallelRunStep.
        55_azureml-execution-<node id>.txt: build/pull image and start the container.
        65_job_prep-<node id>.txt: prepare control code and data for a job.
        70_driver_log_<node seq>.txt: start scheduling/processing.
        75_job_post-<node id>.txt: release a job, includes uploading data, senting run history, etc.
        process_info.json: the process info of running worker docker instances.
        process_status.json: the status of worker docker instances.

    2. logs: ParallelRunStep scheduling and processing logs. See below for details of this folder.

    Note:
    <node id> is like "tvmps_ca98a48189a073b411a7b26c6f89bc98a8c8e55b1b804916b2a0ce92bbce6d3e_p",
        which identifies a node in a compute cluster.
    <node seq> is a short identifer to group logs.
        For non-Parallel Task, <node seq> is the ip address of the node.
        For Parallel Task, it is a sequential number as a node can leave and join again.
    You can find <node id> and <node seq> from logs/sys/node/<node seq>/_boot.txt.


ParallelRunStep has two major parts:
 1. Scheduling, progress tracking and file concatenation for append_row.
 2. Processing mini batch by calling the entry script.
    The agent manager on each node start agents.
    An agent gets mini batch and calls the entry script against the mini batch.

    The "logs" folder has user, sys and perf sub folders.
    The user folder includes messages from the entry script in processing mini batches.
    The sys folder includes messages from #1 and non-entry script log from #2.
    The perf folder includes periodical checking result of resource usage.

In majority case, users can find the processing messages from the user folder.
Users need to check sys folder for messages beyond processing mini batches.
logs/
    azureml/: Logs from azureml dependencies. e.g. azureml.dataprep
    user/   : Logs generated when loading and running user's scripts.
        error/            : Logs of errors encountered while loading and running entry script.
        stderr/           : stderr output of user's scripts.
        stdout/           : stdout output of user's scripts.
        entry_script_log/ : Logs generated by loggers of EntryScript()
            <node seq>     :
                processNNN.log.txt  : Logs generated by loggers of EntryScript() from each process.
    sys/    : Logs generated by ParallelRunStep scripts.
        error/      : System errors encountered in ParallelRunStep scripts.
        warning/    : Warning logs
        job_report/: Mini-batch processing results, which can be used to check mini-batch distribution, succeeded or
                     failed mini-batch.
            node_summary.csv    : Mini-batch processing summary report for each node.
            process_summary.csv : Mini-batch processing summary report for each process.
            processed_mini-batches.csv : Detailed records of all mini-batch results.
        node/   : Logs from nodes. each node has a sub folder
            <node seq>
                _boot.txt           : Log for extracting and then starting the sys environment.
                _installed_packages.txt:    pip freeze result from the user environment.
                _main.txt           : Log for the node main file, which starts the task server and agent manager.
                                        The stdout/stderr from an agent will be printed in this file.
                _master_poller.txt  : Log for the master poller.
                _task_server.txt    : Log for the task server. Task server provides an asynchronous TCP server to
                                      process mini-batch and track progress.
                node-progress.csv   : The cumulative count of different mini-batch run result on the node along time.
                processNNN.mini-batch.csv : Mini-batch picked and processed by the process.
                processNNN.stderr.txt     : The stderr returned from the agent.
                                            We capture the stderr from the entry script. Some errors we cannot catch,
                                             such as terminate error from underlier c/c++ lib, will sink to this file.
                processNNN.stdout.txt     : The stdout returned from the agent, excludes print() in the entry script.
                                            print() from the entry script sinks to the one under user/stdout/.
                processNNN.txt      : Logs of the process.
        node_launcher/ : Logs of the node launcher. Node launcher is to launch the script on all nodes.

        master_role.<timestamp>_<node seq>.txt :
            This file provides the master role (also known as the orchestrator) view of the running job.
            Includes task creation, progress monitoring, the run result.
            One node will acquire the master role when the job starts.
            If the master role or the node running the master role failed, another will acquire the master role.
            A new master role will generate a new log file.

    perf/       : Periodical checking results of the resource usage for each node here.
                Set --resource_monitor_interval to change the checking interval in seconds.
                The default interval is 600, which is approximate to 10 minutes.
                Set the value to 0 to stop the monitoring.
        <node seq>
            os_processes: The resource usage of all running processes in the node.
                On Linux, the command is 'ps'. On Windows, it is 'tasklist'.
            node_disk_usage.csv          : Detailed disk usage of the node.
            node_resource_usage.csv      : Resource usage overview of the node.
            processes_resource_usage.csv : Resource usage overview of each process.
    job_error.<timestamp>.txt: This shows errors in loading, calling init() and calling run() of the entry script.
        You can find the node and the process which runs into errors.
        Then you can check the node/process for detail error.
        It will stop if the number of errors exceeding 1000.
    job_progress_overview.<timestamp>.txt : This file provides a high-level info about the number of mini-batches
         (also known as tasks) created so far and number of mini-batches processed so far.
         At this end, it shows the result of the job.
         If the job failed, it will show the error message and where to start the troubleshooting.
         This file name has year, month and day in UTC timezone.
         A new file will be generated for each day to keep one file in user friendly size.

Links:
https://channel9.msdn.com/Shows/AI-Show/Batch-Inference-using-Azure-Machine-Learning
https://aka.ms/batch-inference-notebooks
https://aka.ms/batch-inference-documentation
Troubleshooting the ParallelRunStep: https://aka.ms/prstsg
    